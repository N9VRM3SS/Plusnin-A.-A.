Отчет по лабораторной работе #5 выполнил(а):
- Плюснин Арсений Алексеевич
- НМТ233001
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |


Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity

##Задание 1. Найдите внутри C# скрипта “коэффициент корреляции ” и сделать выводы о том, как он влияет на обучение модели.
Если пытаться найти клоэфициенты корреляции, то здесь можно найти сильное корреллирование между действиями агентов с получаемыми вознаграждениями (например, движение в сторону цели приводит к положительному вознаграждению), агент быстрее находит эффективные стратегии.
Также корреляция прослеживается между векторной скоростью агента и его положением в пространстве, относительно цели, т.е. при слишком высоких значениях скорости агент начал бы "улетать" и точность начала бы падать.

## Задание 2. Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров

batch_size: Больший batch_size может ускорить обучение и улучшить стабильность градиентов, но съест больше памяти.

learning_rate: Более высокий темп обучения ускоряет обучение, но может привести к нестабильности, грубо говоря, он просто может перескочить точку достаточного обучения и начать переобучаться. Более низкий же обеспечивает стабильность, но, соответственно, замедляет обучение.

max_steps: Определяет длительность обучения. Слишком маленькое значение может привести к недообучению, слишком большое — переобучению, что достаточно логично.

learningrateschedule: Линейное снижение learning_rat'а помогает начать обучение быстро и постепенно замедлять чтобы не упустить "пик" стабильности. Крутая штука, в общем.

## Задание 3
Задание 3. Приведите примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. В каких случаях проще использовать ML-агент, а не писать программную реализацию решения? 
В данном примере рассматриваются алгоритмы поиска маршрутов, а на сегодняшний день есть множество более эффективных и простых алгориртмов, выполняющих ту же задачу, т.е. теж NavMesh. Всё же, разработать полноценную нейронку для подобного - дорого, к тому же, как по мне, нестабильно. Про ресурсоёмкость, в общем, стоило бы промолчать, думаю, что ещё рано полноценно применять это в играх, но могу быть не прав, если есть что-то против, буду очень рад услышать/прочитать (https://t.me/Volodemare). Возможно можно взять данную нейронку более обширно и применять её для навигации непесей в целом, например в каких-либо стратегиях.
## Выводы
Слишком много времени заняла данная работа, так как возникали конфликты на фоне разных версий питона, неразбериха с библиотеками, в процессе где-то напортачил так, что еще и предыдущие проекты слетели, но по итогу, не знаю насколько правильно все выполнено, но что выгрузил, то и получил

Графики:
![image](https://github.com/user-attachments/assets/1ba99d06-3bf2-4c66-8af3-132ce520a316)


## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
